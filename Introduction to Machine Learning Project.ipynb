{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning: Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile carrier Megaline has found out that many of their subscribers use\n",
    "legacy plans. They want to develop a model that would analyze subscribers'\n",
    "behavior and recommend one of Megaline's newer plans: Smart or Ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have access to behavior data about subscribers who have already\n",
    "switched to the new plans (from the project for the Statistical Data Analysis\n",
    "course). For this classification task, you need to develop a model that will pick\n",
    "the right plan. Since you’ve already performed the data preprocessing step,\n",
    "you can move straight to creating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a model with the highest possible accuracy. In this project, the\n",
    "threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description\n",
    "Every observation in the dataset contains monthly behavior information about\n",
    "one user. \n",
    "\n",
    "The information given is as follows:\n",
    "\n",
    "сalls — number of calls,\n",
    "\n",
    "minutes — total call duration in minutes,\n",
    "\n",
    "messages — number of text messages,\n",
    "\n",
    "mb_used — Internet traffic used in MB,\n",
    "\n",
    "is_ultra — plan for the current month (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1) Open and look through the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No missing values and data types are okay. This is a classification task and the target is is_ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Split the source data into a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.40, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, df_test = train_test_split(df_valid, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 59.98755444928439 %\n"
     ]
    }
   ],
   "source": [
    "print('training set:', (len(df_train)/len(df))*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set: 20.00622277535781 %\n"
     ]
    }
   ],
   "source": [
    "print('validation set:', (len(df_valid)/len(df))*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: 20.00622277535781 %\n"
     ]
    }
   ],
   "source": [
    "print('test set:', (len(df_test)/len(df))*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60% of data is training set, 20% of data is validation set, and 20% is test set. The small error is okay and inevitable with computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features= df_train.drop(['is_ultra'], axis=1)\n",
    "df_train_target= df_train['is_ultra']\n",
    "df_valid_features= df_valid.drop(['is_ultra'], axis=1)\n",
    "df_valid_target= df_valid['is_ultra']\n",
    "df_test_features= df_test.drop(['is_ultra'], axis=1)\n",
    "df_test_target= df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3) Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 depth 0.0996150854425607 accuracy\n",
      "2 depth 0.17738877218684745 accuracy\n",
      "3 depth 0.2003996020871055 accuracy\n",
      "4 depth 0.20261580245697808 accuracy\n",
      "5 depth 0.2027820760725395 accuracy\n",
      "6 depth 0.180638804456413 accuracy\n",
      "7 depth 0.1754232379119819 accuracy\n",
      "8 depth 0.15146556145560508 accuracy\n",
      "9 depth 0.12579566071179393 accuracy\n",
      "10 depth 0.09585009167126413 accuracy\n",
      "11 depth 0.011349014708507577 accuracy\n",
      "12 depth -0.03667827853659311 accuracy\n",
      "13 depth -0.09666987775708935 accuracy\n",
      "14 depth -0.12151926550692993 accuracy\n",
      "15 depth -0.168739600593508 accuracy\n",
      "16 depth -0.2429972039987995 accuracy\n",
      "17 depth -0.2902803568735357 accuracy\n",
      "18 depth -0.260375657967886 accuracy\n",
      "19 depth -0.2960351374268262 accuracy\n",
      "20 depth -0.3157074783348359 accuracy\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,21):\n",
    "    model = DecisionTreeRegressor(random_state=12345, max_depth=depth)\n",
    "    model.fit(df_train_features, df_train_target)\n",
    "\n",
    "    print(depth, 'depth', model.score(df_valid_features, df_valid_target), 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree has low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 trees: 0.20356829708878155 accuracy\n",
      "200 trees: 0.20953792479546873 accuracy\n",
      "300 trees: 0.21095686794759216 accuracy\n",
      "400 trees: 0.2150138615743652 accuracy\n",
      "500 trees: 0.2134420781763512 accuracy\n",
      "600 trees: 0.21547343558595988 accuracy\n",
      "700 trees: 0.2176197137871999 accuracy\n",
      "800 trees: 0.21794037718443326 accuracy\n",
      "900 trees: 0.21745636829908854 accuracy\n",
      "1000 trees: 0.21821177792928226 accuracy\n"
     ]
    }
   ],
   "source": [
    "for trees in range(100,1001,100):\n",
    "\n",
    "    model = RandomForestRegressor(random_state=12345, n_estimators=trees)\n",
    "    model.fit(df_train_features, df_train_target)\n",
    "\n",
    "    print(trees, 'trees:', model.score(df_valid_features, df_valid_target), 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest has only about 21% accuracy. This is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7589424572317263"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(df_train_features, df_train_target)\n",
    "\n",
    "model.score(df_valid_features, df_valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression has the highest accuracy at 75% accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decision Tree and Random Forest both have low accuracy. The Logistic Regression model has the highest accuracy, so I will use this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Check the quality of the model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402799377916018"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(df_test_features, df_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a pretty good accuracy for the test set. It is accurate about 74% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Additional task: sanity check the model. This data is more complex than what you’re used to working with, so it’s okay if it doesn’t work out. We'll take a closer look at it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402799377916018"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(df_test_features, df_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "choices = [0,1]\n",
    "random_predictions = np.random.choice(choices, size=len(df_test_target))\n",
    "accuracy = accuracy_score(df_test_target, random_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49144634525660963"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model performs better than chance so it passes the sanity check."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
